{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae0e0b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Using cached langchain-0.3.27-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting langchain-community\n",
      "  Downloading langchain_community-0.3.29-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.55.4-py3-none-any.whl.metadata (41 kB)\n",
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-5.1.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting langchain-core<1.0.0,>=0.3.72 (from langchain)\n",
      "  Using cached langchain_core-0.3.75-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.9 (from langchain)\n",
      "  Using cached langchain_text_splitters-0.3.10-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting langsmith>=0.1.17 (from langchain)\n",
      "  Using cached langsmith-0.4.20-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting pydantic<3.0.0,>=2.7.4 (from langchain)\n",
      "  Using cached pydantic-2.11.7-py3-none-any.whl.metadata (67 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Using cached sqlalchemy-2.0.43-cp312-cp312-win_amd64.whl.metadata (9.8 kB)\n",
      "Collecting requests<3,>=2 (from langchain)\n",
      "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting PyYAML>=5.3 (from langchain)\n",
      "  Using cached PyYAML-6.0.2-cp312-cp312-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting tenacity!=8.4.0,<10.0.0,>=8.1.0 (from langchain-core<1.0.0,>=0.3.72->langchain)\n",
      "  Using cached tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<1.0.0,>=0.3.72->langchain)\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\eourm\\anaconda3\\envs\\llm\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (4.15.0)\n",
      "Requirement already satisfied: packaging>=23.2 in c:\\users\\eourm\\anaconda3\\envs\\llm\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain)\n",
      "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting pip>=25.2 (from langchain-text-splitters<1.0.0,>=0.3.9->langchain)\n",
      "  Using cached pip-25.2-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Using cached pydantic_core-2.33.2-cp312-cp312-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Using cached typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests<3,>=2->langchain)\n",
      "  Using cached charset_normalizer-3.4.3-cp312-cp312-win_amd64.whl.metadata (37 kB)\n",
      "Collecting idna<4,>=2.5 (from requests<3,>=2->langchain)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2->langchain)\n",
      "  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests<3,>=2->langchain)\n",
      "  Using cached certifi-2025.8.3-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting greenlet>=1 (from SQLAlchemy<3,>=1.4->langchain)\n",
      "  Using cached greenlet-3.2.4-cp312-cp312-win_amd64.whl.metadata (4.2 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain-community)\n",
      "  Downloading aiohttp-3.12.15-cp312-cp312-win_amd64.whl.metadata (7.9 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.6.7 (from langchain-community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.10.1 (from langchain-community)\n",
      "  Downloading pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
      "  Downloading httpx_sse-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Collecting numpy>=1.26.2 (from langchain-community)\n",
      "  Using cached numpy-2.3.2-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading frozenlist-1.7.0-cp312-cp312-win_amd64.whl.metadata (19 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading multidict-6.6.4-cp312-cp312-win_amd64.whl.metadata (5.4 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading propcache-0.3.2-cp312-cp312-win_amd64.whl.metadata (12 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading yarl-1.20.1-cp312-cp312-win_amd64.whl.metadata (76 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.6.7->langchain-community)\n",
      "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.6.7->langchain-community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.10.1->langchain-community)\n",
      "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.6.7->langchain-community)\n",
      "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting filelock (from transformers)\n",
      "  Downloading filelock-3.19.1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.34.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.34.4-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Using cached regex-2025.7.34-cp312-cp312-win_amd64.whl.metadata (41 kB)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Downloading tokenizers-0.21.4-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Downloading safetensors-0.6.2-cp38-abi3-win_amd64.whl.metadata (4.1 kB)\n",
      "Collecting tqdm>=4.27 (from transformers)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.34.0->transformers)\n",
      "  Downloading fsspec-2025.7.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting torch>=1.11.0 (from sentence-transformers)\n",
      "  Downloading torch-2.8.0-cp312-cp312-win_amd64.whl.metadata (30 kB)\n",
      "Collecting scikit-learn (from sentence-transformers)\n",
      "  Downloading scikit_learn-1.7.1-cp312-cp312-win_amd64.whl.metadata (11 kB)\n",
      "Collecting scipy (from sentence-transformers)\n",
      "  Downloading scipy-1.16.1-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting Pillow (from sentence-transformers)\n",
      "  Downloading pillow-11.3.0-cp312-cp312-win_amd64.whl.metadata (9.2 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from langsmith>=0.1.17->langchain)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting orjson>=3.9.14 (from langsmith>=0.1.17->langchain)\n",
      "  Using cached orjson-3.11.3-cp312-cp312-win_amd64.whl.metadata (43 kB)\n",
      "Collecting requests-toolbelt>=1.0.0 (from langsmith>=0.1.17->langchain)\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting zstandard>=0.23.0 (from langsmith>=0.1.17->langchain)\n",
      "  Using cached zstandard-0.24.0-cp312-cp312-win_amd64.whl.metadata (3.2 kB)\n",
      "Collecting anyio (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain)\n",
      "  Using cached anyio-4.10.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain)\n",
      "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain)\n",
      "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting sympy>=1.13.3 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting jinja2 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\eourm\\anaconda3\\envs\\llm\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (78.1.1)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\eourm\\anaconda3\\envs\\llm\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Collecting sniffio>=1.1 (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch>=1.11.0->sentence-transformers)\n",
      "  Downloading MarkupSafe-3.0.2-cp312-cp312-win_amd64.whl.metadata (4.1 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn->sentence-transformers)\n",
      "  Downloading joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->sentence-transformers)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Using cached langchain-0.3.27-py3-none-any.whl (1.0 MB)\n",
      "Using cached langchain_core-0.3.75-py3-none-any.whl (443 kB)\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Using cached langchain_text_splitters-0.3.10-py3-none-any.whl (34 kB)\n",
      "Using cached pydantic-2.11.7-py3-none-any.whl (444 kB)\n",
      "Using cached pydantic_core-2.33.2-cp312-cp312-win_amd64.whl (2.0 MB)\n",
      "Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Using cached charset_normalizer-3.4.3-cp312-cp312-win_amd64.whl (107 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached sqlalchemy-2.0.43-cp312-cp312-win_amd64.whl (2.1 MB)\n",
      "Using cached tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Downloading langchain_community-0.3.29-py3-none-any.whl (2.5 MB)\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   ----------------------------- ---------- 1.8/2.5 MB 9.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.5/2.5 MB 7.6 MB/s eta 0:00:00\n",
      "Downloading aiohttp-3.12.15-cp312-cp312-win_amd64.whl (450 kB)\n",
      "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading httpx_sse-0.4.1-py3-none-any.whl (8.1 kB)\n",
      "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Downloading multidict-6.6.4-cp312-cp312-win_amd64.whl (46 kB)\n",
      "Downloading pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading yarl-1.20.1-cp312-cp312-win_amd64.whl (86 kB)\n",
      "Downloading transformers-4.55.4-py3-none-any.whl (11.3 MB)\n",
      "   ---------------------------------------- 0.0/11.3 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 1.8/11.3 MB 8.4 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 3.7/11.3 MB 9.1 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 5.8/11.3 MB 9.0 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 7.9/11.3 MB 9.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 9.4/11.3 MB 9.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.0/11.3 MB 8.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.3/11.3 MB 8.4 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.34.4-py3-none-any.whl (561 kB)\n",
      "   ---------------------------------------- 0.0/561.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 561.5/561.5 kB 4.8 MB/s eta 0:00:00\n",
      "Downloading tokenizers-0.21.4-cp39-abi3-win_amd64.whl (2.5 MB)\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   -------------------- ------------------- 1.3/2.5 MB 8.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 2.4/2.5 MB 6.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.5/2.5 MB 5.7 MB/s eta 0:00:00\n",
      "Downloading sentence_transformers-5.1.0-py3-none-any.whl (483 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "Using cached certifi-2025.8.3-py3-none-any.whl (161 kB)\n",
      "Downloading frozenlist-1.7.0-cp312-cp312-win_amd64.whl (43 kB)\n",
      "Downloading fsspec-2025.7.0-py3-none-any.whl (199 kB)\n",
      "Using cached greenlet-3.2.4-cp312-cp312-win_amd64.whl (299 kB)\n",
      "Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached langsmith-0.4.20-py3-none-any.whl (377 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Using cached numpy-2.3.2-cp312-cp312-win_amd64.whl (12.8 MB)\n",
      "Using cached orjson-3.11.3-cp312-cp312-win_amd64.whl (131 kB)\n",
      "Using cached pip-25.2-py3-none-any.whl (1.8 MB)\n",
      "Downloading propcache-0.3.2-cp312-cp312-win_amd64.whl (41 kB)\n",
      "Downloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Using cached PyYAML-6.0.2-cp312-cp312-win_amd64.whl (156 kB)\n",
      "Using cached regex-2025.7.34-cp312-cp312-win_amd64.whl (275 kB)\n",
      "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Downloading safetensors-0.6.2-cp38-abi3-win_amd64.whl (320 kB)\n",
      "Downloading torch-2.8.0-cp312-cp312-win_amd64.whl (241.3 MB)\n",
      "   ---------------------------------------- 0.0/241.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.0/241.3 MB 5.0 MB/s eta 0:00:48\n",
      "   ---------------------------------------- 2.1/241.3 MB 5.3 MB/s eta 0:00:45\n",
      "   ---------------------------------------- 2.9/241.3 MB 4.7 MB/s eta 0:00:52\n",
      "    --------------------------------------- 3.9/241.3 MB 4.6 MB/s eta 0:00:52\n",
      "    --------------------------------------- 5.2/241.3 MB 4.9 MB/s eta 0:00:49\n",
      "   - -------------------------------------- 6.8/241.3 MB 5.4 MB/s eta 0:00:44\n",
      "   - -------------------------------------- 8.1/241.3 MB 5.5 MB/s eta 0:00:43\n",
      "   - -------------------------------------- 9.2/241.3 MB 5.4 MB/s eta 0:00:43\n",
      "   - -------------------------------------- 10.5/241.3 MB 5.5 MB/s eta 0:00:42\n",
      "   - -------------------------------------- 12.1/241.3 MB 5.7 MB/s eta 0:00:41\n",
      "   -- ------------------------------------- 13.1/241.3 MB 5.6 MB/s eta 0:00:42\n",
      "   -- ------------------------------------- 14.4/241.3 MB 5.7 MB/s eta 0:00:41\n",
      "   -- ------------------------------------- 16.0/241.3 MB 5.8 MB/s eta 0:00:39\n",
      "   -- ------------------------------------- 17.3/241.3 MB 5.8 MB/s eta 0:00:39\n",
      "   --- ------------------------------------ 19.4/241.3 MB 6.0 MB/s eta 0:00:37\n",
      "   --- ------------------------------------ 21.5/241.3 MB 6.3 MB/s eta 0:00:35\n",
      "   --- ------------------------------------ 23.6/241.3 MB 6.5 MB/s eta 0:00:34\n",
      "   ---- ----------------------------------- 25.7/241.3 MB 6.7 MB/s eta 0:00:33\n",
      "   ---- ----------------------------------- 28.0/241.3 MB 6.9 MB/s eta 0:00:31\n",
      "   ---- ----------------------------------- 29.9/241.3 MB 7.0 MB/s eta 0:00:31\n",
      "   ----- ---------------------------------- 32.2/241.3 MB 7.2 MB/s eta 0:00:30\n",
      "   ----- ---------------------------------- 34.3/241.3 MB 7.3 MB/s eta 0:00:29\n",
      "   ----- ---------------------------------- 36.2/241.3 MB 7.4 MB/s eta 0:00:28\n",
      "   ------ --------------------------------- 38.5/241.3 MB 7.5 MB/s eta 0:00:28\n",
      "   ------ --------------------------------- 40.6/241.3 MB 7.6 MB/s eta 0:00:27\n",
      "   ------- -------------------------------- 43.0/241.3 MB 7.7 MB/s eta 0:00:26\n",
      "   ------- -------------------------------- 45.1/241.3 MB 7.8 MB/s eta 0:00:26\n",
      "   ------- -------------------------------- 46.9/241.3 MB 7.9 MB/s eta 0:00:25\n",
      "   -------- ------------------------------- 49.0/241.3 MB 7.9 MB/s eta 0:00:25\n",
      "   -------- ------------------------------- 51.1/241.3 MB 8.0 MB/s eta 0:00:24\n",
      "   -------- ------------------------------- 53.5/241.3 MB 8.1 MB/s eta 0:00:24\n",
      "   --------- ------------------------------ 55.6/241.3 MB 8.1 MB/s eta 0:00:23\n",
      "   --------- ------------------------------ 57.7/241.3 MB 8.1 MB/s eta 0:00:23\n",
      "   --------- ------------------------------ 59.5/241.3 MB 8.2 MB/s eta 0:00:23\n",
      "   ---------- ----------------------------- 60.8/241.3 MB 8.1 MB/s eta 0:00:23\n",
      "   ---------- ----------------------------- 61.9/241.3 MB 8.1 MB/s eta 0:00:23\n",
      "   ---------- ----------------------------- 63.4/241.3 MB 8.0 MB/s eta 0:00:23\n",
      "   ---------- ----------------------------- 64.7/241.3 MB 8.0 MB/s eta 0:00:23\n",
      "   ---------- ----------------------------- 66.1/241.3 MB 7.9 MB/s eta 0:00:23\n",
      "   ----------- ---------------------------- 67.1/241.3 MB 7.9 MB/s eta 0:00:23\n",
      "   ----------- ---------------------------- 68.4/241.3 MB 7.8 MB/s eta 0:00:23\n",
      "   ----------- ---------------------------- 69.7/241.3 MB 7.7 MB/s eta 0:00:23\n",
      "   ----------- ---------------------------- 71.0/241.3 MB 7.7 MB/s eta 0:00:23\n",
      "   ----------- ---------------------------- 72.4/241.3 MB 7.7 MB/s eta 0:00:23\n",
      "   ------------ --------------------------- 73.4/241.3 MB 7.6 MB/s eta 0:00:23\n",
      "   ------------ --------------------------- 73.9/241.3 MB 7.5 MB/s eta 0:00:23\n",
      "   ------------ --------------------------- 75.0/241.3 MB 7.4 MB/s eta 0:00:23\n",
      "   ------------ --------------------------- 76.0/241.3 MB 7.4 MB/s eta 0:00:23\n",
      "   ------------ --------------------------- 77.1/241.3 MB 7.3 MB/s eta 0:00:23\n",
      "   ------------ --------------------------- 78.1/241.3 MB 7.3 MB/s eta 0:00:23\n",
      "   ------------- -------------------------- 79.2/241.3 MB 7.2 MB/s eta 0:00:23\n",
      "   ------------- -------------------------- 80.5/241.3 MB 7.2 MB/s eta 0:00:23\n",
      "   ------------- -------------------------- 81.5/241.3 MB 7.2 MB/s eta 0:00:23\n",
      "   ------------- -------------------------- 83.1/241.3 MB 7.2 MB/s eta 0:00:23\n",
      "   ------------- -------------------------- 84.4/241.3 MB 7.2 MB/s eta 0:00:22\n",
      "   -------------- ------------------------- 86.0/241.3 MB 7.2 MB/s eta 0:00:22\n",
      "   -------------- ------------------------- 87.6/241.3 MB 7.2 MB/s eta 0:00:22\n",
      "   -------------- ------------------------- 88.9/241.3 MB 7.1 MB/s eta 0:00:22\n",
      "   -------------- ------------------------- 89.9/241.3 MB 7.1 MB/s eta 0:00:22\n",
      "   --------------- ------------------------ 90.7/241.3 MB 7.1 MB/s eta 0:00:22\n",
      "   --------------- ------------------------ 92.0/241.3 MB 7.0 MB/s eta 0:00:22\n",
      "   --------------- ------------------------ 93.3/241.3 MB 7.0 MB/s eta 0:00:22\n",
      "   --------------- ------------------------ 94.4/241.3 MB 7.0 MB/s eta 0:00:22\n",
      "   --------------- ------------------------ 95.4/241.3 MB 7.0 MB/s eta 0:00:21\n",
      "   ---------------- ----------------------- 97.0/241.3 MB 6.9 MB/s eta 0:00:21\n",
      "   ---------------- ----------------------- 98.0/241.3 MB 6.9 MB/s eta 0:00:21\n",
      "   ---------------- ----------------------- 99.6/241.3 MB 6.9 MB/s eta 0:00:21\n",
      "   ---------------- ----------------------- 101.2/241.3 MB 6.9 MB/s eta 0:00:21\n",
      "   ---------------- ----------------------- 102.2/241.3 MB 6.9 MB/s eta 0:00:21\n",
      "   ----------------- ---------------------- 103.8/241.3 MB 6.9 MB/s eta 0:00:20\n",
      "   ----------------- ---------------------- 105.1/241.3 MB 6.9 MB/s eta 0:00:20\n",
      "   ----------------- ---------------------- 106.4/241.3 MB 6.9 MB/s eta 0:00:20\n",
      "   ----------------- ---------------------- 108.0/241.3 MB 6.9 MB/s eta 0:00:20\n",
      "   ------------------ --------------------- 109.3/241.3 MB 6.9 MB/s eta 0:00:20\n",
      "   ------------------ --------------------- 110.9/241.3 MB 6.9 MB/s eta 0:00:19\n",
      "   ------------------ --------------------- 112.2/241.3 MB 6.9 MB/s eta 0:00:19\n",
      "   ------------------ --------------------- 113.5/241.3 MB 6.9 MB/s eta 0:00:19\n",
      "   ------------------- -------------------- 114.8/241.3 MB 6.9 MB/s eta 0:00:19\n",
      "   ------------------- -------------------- 116.4/241.3 MB 6.9 MB/s eta 0:00:19\n",
      "   ------------------- -------------------- 117.7/241.3 MB 6.9 MB/s eta 0:00:18\n",
      "   ------------------- -------------------- 119.0/241.3 MB 6.9 MB/s eta 0:00:18\n",
      "   ------------------- -------------------- 120.6/241.3 MB 6.9 MB/s eta 0:00:18\n",
      "   -------------------- ------------------- 121.9/241.3 MB 6.9 MB/s eta 0:00:18\n",
      "   -------------------- ------------------- 122.9/241.3 MB 6.9 MB/s eta 0:00:18\n",
      "   -------------------- ------------------- 124.5/241.3 MB 6.8 MB/s eta 0:00:18\n",
      "   -------------------- ------------------- 125.8/241.3 MB 6.9 MB/s eta 0:00:17\n",
      "   --------------------- ------------------ 127.4/241.3 MB 6.8 MB/s eta 0:00:17\n",
      "   --------------------- ------------------ 128.7/241.3 MB 6.8 MB/s eta 0:00:17\n",
      "   --------------------- ------------------ 130.5/241.3 MB 6.9 MB/s eta 0:00:17\n",
      "   --------------------- ------------------ 132.6/241.3 MB 6.9 MB/s eta 0:00:16\n",
      "   ---------------------- ----------------- 135.0/241.3 MB 6.9 MB/s eta 0:00:16\n",
      "   ---------------------- ----------------- 137.1/241.3 MB 7.0 MB/s eta 0:00:15\n",
      "   ----------------------- ---------------- 139.2/241.3 MB 7.0 MB/s eta 0:00:15\n",
      "   ----------------------- ---------------- 141.3/241.3 MB 7.0 MB/s eta 0:00:15\n",
      "   ----------------------- ---------------- 143.4/241.3 MB 7.1 MB/s eta 0:00:14\n",
      "   ------------------------ --------------- 145.5/241.3 MB 7.1 MB/s eta 0:00:14\n",
      "   ------------------------ --------------- 147.6/241.3 MB 7.1 MB/s eta 0:00:14\n",
      "   ------------------------ --------------- 149.9/241.3 MB 7.1 MB/s eta 0:00:13\n",
      "   ------------------------- -------------- 151.8/241.3 MB 7.2 MB/s eta 0:00:13\n",
      "   ------------------------- -------------- 153.9/241.3 MB 7.2 MB/s eta 0:00:13\n",
      "   ------------------------- -------------- 156.2/241.3 MB 7.2 MB/s eta 0:00:12\n",
      "   -------------------------- ------------- 158.3/241.3 MB 7.3 MB/s eta 0:00:12\n",
      "   -------------------------- ------------- 159.9/241.3 MB 7.3 MB/s eta 0:00:12\n",
      "   -------------------------- ------------- 161.2/241.3 MB 7.3 MB/s eta 0:00:12\n",
      "   --------------------------- ------------ 163.3/241.3 MB 7.3 MB/s eta 0:00:11\n",
      "   --------------------------- ------------ 165.4/241.3 MB 7.3 MB/s eta 0:00:11\n",
      "   --------------------------- ------------ 167.5/241.3 MB 7.3 MB/s eta 0:00:11\n",
      "   ---------------------------- ----------- 169.9/241.3 MB 7.3 MB/s eta 0:00:10\n",
      "   ---------------------------- ----------- 171.7/241.3 MB 7.4 MB/s eta 0:00:10\n",
      "   ---------------------------- ----------- 174.1/241.3 MB 7.4 MB/s eta 0:00:10\n",
      "   ----------------------------- ---------- 176.2/241.3 MB 7.4 MB/s eta 0:00:09\n",
      "   ----------------------------- ---------- 178.0/241.3 MB 7.4 MB/s eta 0:00:09\n",
      "   ----------------------------- ---------- 180.4/241.3 MB 7.5 MB/s eta 0:00:09\n",
      "   ------------------------------ --------- 182.5/241.3 MB 7.5 MB/s eta 0:00:08\n",
      "   ------------------------------ --------- 184.5/241.3 MB 7.5 MB/s eta 0:00:08\n",
      "   ------------------------------ --------- 186.4/241.3 MB 7.5 MB/s eta 0:00:08\n",
      "   ------------------------------- -------- 188.2/241.3 MB 7.5 MB/s eta 0:00:08\n",
      "   ------------------------------- -------- 190.1/241.3 MB 7.5 MB/s eta 0:00:07\n",
      "   ------------------------------- -------- 191.6/241.3 MB 7.5 MB/s eta 0:00:07\n",
      "   -------------------------------- ------- 194.0/241.3 MB 7.6 MB/s eta 0:00:07\n",
      "   -------------------------------- ------- 196.3/241.3 MB 7.6 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 198.4/241.3 MB 7.6 MB/s eta 0:00:06\n",
      "   --------------------------------- ------ 200.5/241.3 MB 7.6 MB/s eta 0:00:06\n",
      "   --------------------------------- ------ 202.9/241.3 MB 7.6 MB/s eta 0:00:06\n",
      "   --------------------------------- ------ 204.7/241.3 MB 7.7 MB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 207.1/241.3 MB 7.7 MB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 209.5/241.3 MB 7.7 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 211.3/241.3 MB 7.7 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 213.6/241.3 MB 7.7 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 215.7/241.3 MB 7.8 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 218.1/241.3 MB 7.8 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 220.2/241.3 MB 7.8 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 221.8/241.3 MB 7.8 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 223.1/241.3 MB 7.8 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 225.2/241.3 MB 7.8 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 227.3/241.3 MB 7.8 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 229.1/241.3 MB 7.8 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 231.2/241.3 MB 7.8 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 233.3/241.3 MB 7.8 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 235.1/241.3 MB 7.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  237.0/241.3 MB 7.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  238.8/241.3 MB 7.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  241.2/241.3 MB 7.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  241.2/241.3 MB 7.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  241.2/241.3 MB 7.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  241.2/241.3 MB 7.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  241.2/241.3 MB 7.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  241.2/241.3 MB 7.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 241.3/241.3 MB 7.7 MB/s eta 0:00:00\n",
      "Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "   ---------------------------------------- 0.0/6.3 MB ? eta -:--:--\n",
      "   ----------- ---------------------------- 1.8/6.3 MB 9.1 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 3.7/6.3 MB 9.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 5.8/6.3 MB 9.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.3/6.3 MB 9.0 MB/s eta 0:00:00\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 536.2/536.2 kB 4.4 MB/s eta 0:00:00\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Using cached zstandard-0.24.0-cp312-cp312-win_amd64.whl (505 kB)\n",
      "Using cached anyio-4.10.0-py3-none-any.whl (107 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading filelock-3.19.1-py3-none-any.whl (15 kB)\n",
      "Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Downloading MarkupSafe-3.0.2-cp312-cp312-win_amd64.whl (15 kB)\n",
      "Downloading networkx-3.5-py3-none-any.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ------------------------------------ --- 1.8/2.0 MB 11.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.0/2.0 MB 9.4 MB/s eta 0:00:00\n",
      "Downloading pillow-11.3.0-cp312-cp312-win_amd64.whl (7.0 MB)\n",
      "   ---------------------------------------- 0.0/7.0 MB ? eta -:--:--\n",
      "   ------------ --------------------------- 2.1/7.0 MB 10.7 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 4.2/7.0 MB 10.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 6.3/7.0 MB 10.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 7.0/7.0 MB 9.4 MB/s eta 0:00:00\n",
      "Downloading scikit_learn-1.7.1-cp312-cp312-win_amd64.whl (8.7 MB)\n",
      "   ---------------------------------------- 0.0/8.7 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 1.6/8.7 MB 7.0 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 3.4/8.7 MB 7.7 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 6.0/8.7 MB 9.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 8.1/8.7 MB 9.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  8.7/8.7 MB 9.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.7/8.7 MB 8.1 MB/s eta 0:00:00\n",
      "Downloading joblib-1.5.2-py3-none-any.whl (308 kB)\n",
      "Downloading scipy-1.16.1-cp312-cp312-win_amd64.whl (38.5 MB)\n",
      "   ---------------------------------------- 0.0/38.5 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 2.1/38.5 MB 9.8 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 4.5/38.5 MB 10.7 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 6.8/38.5 MB 10.7 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 8.9/38.5 MB 10.2 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 11.0/38.5 MB 10.3 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 13.4/38.5 MB 10.4 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 14.9/38.5 MB 10.1 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 17.3/38.5 MB 10.0 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 19.4/38.5 MB 10.0 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 21.8/38.5 MB 10.1 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 23.1/38.5 MB 9.7 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 24.9/38.5 MB 9.6 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 26.7/38.5 MB 9.6 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 28.8/38.5 MB 9.5 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 30.9/38.5 MB 9.6 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 32.5/38.5 MB 9.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.6/38.5 MB 9.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 36.7/38.5 MB 9.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.3/38.5 MB 9.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 38.5/38.5 MB 9.1 MB/s eta 0:00:00\n",
      "Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: To modify pip, please run the following command:\n",
      "C:\\Users\\eourm\\anaconda3\\envs\\LLM\\python.exe -m pip install langchain langchain-community transformers sentence-transformers\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain langchain-community transformers sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b00771a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed `num_labels=3` which is incompatible to the `id2label` map of length `2`.\n",
      "You passed `num_labels=3` which is incompatible to the `id2label` map of length `2`.\n",
      "You passed `num_labels=3` which is incompatible to the `id2label` map of length `2`.\n",
      "You passed `num_labels=3` which is incompatible to the `id2label` map of length `2`.\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> '한국 한 한 줄 요약: LangChain helps you build LLM apps easild LLM apps easily.. build LLM apps easps easily.. 한국 한국 한국 한국 한국 한국 한국 한국 한국 한국 한국 한국 한국 한국 한국 한국 한국 한국 한국 한국 한국 한국 한국 한국 한국 한국 한국 한국 한국 한국 한 줄 요약: LangChain helps you build LLM apps you buil'\n"
     ]
    }
   ],
   "source": [
    "# Step 1) Prompt → Model (LLM)\n",
    "from transformers import pipeline\n",
    "from langchain_community.llms import HuggingFacePipeline\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
    "\n",
    "generator = pipeline(\"text2text-generation\",\n",
    "                     model=\"gogamza/kobart-base-v2\",\n",
    "                     max_new_tokens=128)\n",
    "llm = HuggingFacePipeline(pipeline=generator)\n",
    "\n",
    "# 영어 지시가 더 잘 먹힙니다\n",
    "prompt = PromptTemplate.from_template(\"한국어로 한 줄 요약: {text}\")\n",
    "chain = prompt | llm\n",
    "\n",
    "out = chain.invoke({\"text\": \"LangChain helps you build LLM apps easily.\"})\n",
    "print(\">>\", repr(out))   # repr로 빈 문자열 여부 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7403fa39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed `num_labels=3` which is incompatible to the `id2label` map of length `2`.\n",
      "You passed `num_labels=3` which is incompatible to the `id2label` map of length `2`.\n",
      "You passed `num_labels=3` which is incompatible to the `id2label` map of length `2`.\n",
      "You passed `num_labels=3` which is incompatible to the `id2label` map of length `2`.\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "아래 컨텍스트만 근거로 질문에 한국어로 한국어로 간결히 답하세요.\n",
      "[컨텍스트]\n",
      "나는 배고프다.\n",
      "RAG는 검색된 컨텍스트를 활용해 더 정확히 답한다.\n",
      "--- . 잘 잘 잘한다.\n",
      "--- 잘 잘 답한다.\n",
      " 잘 정확히 답한다.\n",
      "--- 잘 잘 잘한다.\n",
      "--- 잘 잘 잘 잘 잘 잘 잘 잘 잘한다.\n",
      " 잘 잘 잘 잘 잘 잘 잘 잘 잘 잘 잘 잘 한국어로 한국어로 한국어로 간결히 답하세요.\n",
      "[럼아아아래 컨텍스트만 근거로 질문에 한국어로 한국어로 한국어로 간결히 답하세요.\n",
      "[\n"
     ]
    }
   ],
   "source": [
    "# Step 2) 검색(Retriever) → Prompt → Model\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.prompts import PromptTemplate\n",
    "from transformers import pipeline\n",
    "from langchain_community.llms import HuggingFacePipeline\n",
    "\n",
    "\n",
    "texts = [\n",
    "\"LangChain은 LLM 앱 개발을 돕는 프레임워크다.\",\n",
    "\"RAG는 검색된 컨텍스트를 활용해 더 정확히 답한다.\",\n",
    "\"나는 배고프다.\",\n",
    "\"졸려 죽겠다.\"\n",
    "]\n",
    "emb = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "db = FAISS.from_texts(texts, emb)\n",
    "\n",
    "\n",
    "question = \"RAG는 무엇인가요?\"\n",
    "context = \"\\n\".join([d.page_content for d in db.similarity_search(question, k=2)])\n",
    "\n",
    "\n",
    "\n",
    "generator = pipeline(\"text2text-generation\",\n",
    "                     model=\"gogamza/kobart-base-v2\",\n",
    "                     max_new_tokens=128)\n",
    "llm = HuggingFacePipeline(pipeline=generator)\n",
    "prompt = PromptTemplate.from_template(\"\"\"\n",
    "아래 컨텍스트만 근거로 질문에 한국어로 간결히 답하세요.\n",
    "[컨텍스트]\n",
    "{ctx}\n",
    "---\n",
    "[질문] {q}\n",
    "[답변]\n",
    "\"\"\")\n",
    "rag_chain = prompt | llm\n",
    "print(rag_chain.invoke({\"ctx\": context, \"q\": question}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1fd2f9f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed `num_labels=3` which is incompatible to the `id2label` map of length `2`.\n",
      "You passed `num_labels=3` which is incompatible to the `id2label` map of length `2`.\n",
      "You passed `num_labels=3` which is incompatible to the `id2label` map of length `2`.\n",
      "You passed `num_labels=3` which is incompatible to the `id2label` map of length `2`.\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "스트만 이용해 질문에 답하세요.\n",
      "[컨텍스트]\n",
      "LangChain은 체인 기반 LLM 앱 프레임워크.\n",
      "커피 한 잔 해야지.\n",
      "---\n",
      "[질문] LLM 앱 프레임워크.\n",
      "커피 한 잔 해야지.\n",
      "---\n",
      "[질문] LangChain은 무엇인가요?\n",
      "[답변]\n",
      "[답변]\n",
      "[답변]\n",
      "[답변]\n",
      "[답변]\n",
      "[컨텍스트만 이용해 질문에 답하세요.\n",
      "[컨텍스트만 이용해 질문에 답하세요.\n",
      "[컨텍스트만 이용해 질문에 답하세요.\n",
      "[컨텍스트만 이용해 질문에 답\n"
     ]
    }
   ],
   "source": [
    "# Step 3) LCEL (LangChain Expression Language)로 전체 파이프 구성\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema.runnable import RunnableLambda\n",
    "from transformers import pipeline\n",
    "from langchain_community.llms import HuggingFacePipeline\n",
    "\n",
    "\n",
    "# 1) 데이터 & 검색기\n",
    "texts = [\"LangChain은 체인 기반 LLM 앱 프레임워크.\", \"FAISS는 빠른 벡터 검색 라이브러리.\", \n",
    "         \"RAG는 검색 기반 생성.\", \"나는 배고프다.\", \"졸려 죽겠다.\", \"커피 한 잔 해야지.\"]\n",
    "emb = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "db = FAISS.from_texts(texts, emb)\n",
    "retriever = RunnableLambda(lambda q: db.similarity_search(q, k=2))\n",
    "\n",
    "\n",
    "# 2) 문서 포맷터\n",
    "fmt = RunnableLambda(lambda docs: \"\\n\".join(d.page_content for d in docs))\n",
    "\n",
    "\n",
    "# 3) 프롬프트 & 모델\n",
    "prompt = PromptTemplate.from_template(\"\"\"\n",
    "컨텍스트만 이용해 질문에 답하세요.\n",
    "[컨텍스트]\n",
    "{context}\n",
    "---\n",
    "[질문] {question}\n",
    "[답변]\n",
    "\"\"\")\n",
    "\n",
    "generator = pipeline(\"text2text-generation\",\n",
    "                     model=\"gogamza/kobart-base-v2\",\n",
    "                     do_sample=False,\n",
    "                     max_new_tokens=128)\n",
    "llm = HuggingFacePipeline(pipeline=generator)\n",
    "\n",
    "\n",
    "# 4) 전체 파이프: 질문(str) → 검색 → 텍스트화 → 프롬프트 바인딩 → LLM\n",
    "chain = (RunnableLambda(lambda x: x)\n",
    "| {\"context\": retriever | fmt, \"question\": RunnableLambda(lambda x: x)}\n",
    "| prompt | llm)\n",
    "\n",
    "\n",
    "print(chain.invoke(\"LangChain은 무엇인가요?\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
